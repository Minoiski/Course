\chapter{ОСНОВНЫЕ ПОНЯТИЯ И ОБЗОР ЛИТЕРАТУРЫ }\label{chap1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Теория управления по прогнозирующей модели}\label{1sec:MPC}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Управление по прогнозирующей модели(MPC)- это продвинутый метод управления, который используется для управления процессом  при одновременном удовлетворении набора ограничений. Главная идея MPC --- использование математической модели управляемого процесса в пространстве состояний для предсказания и оптимизации будущего поведения системы. Он используется в перерабатывающей промышленности на химических и нефтеперерабатывающих заводах с 1980-х годов. В последние годы он также используется в моделях балансировки энергосистем и в силовой электронике. Основным преимуществом MPC является тот факт, что он позволяет оптимизировать текущий временной интервал, учитывая при этом будущие временные интервалы. Это достигается за счет оптимизации конечного временного горизонта, но только на текущем временном интервале. Модели используемые в MPC обычно призваны показать поведение сложных динамических систем. Модели MPC предсказывают изменение в зависимых переменных моделируемой системы, которое будет вызвано изменениями в независимых переменных. Независимые переменные, которые не могут быть [скорректированы? связаны с? adjusted by управлением], воспринимаются как возмущения. Зависимыми переменными в этих процессах представляют  либо задачи управления, либо ограничения на процесс.
MPC использует текущие значения переменных, текущее динамическое состояние процесса, модель, а также значение эталона? reference и ограничения переменных для расчета будущих изменений зависимых переменных. Эти изменения рассчитаны так, чтобы держать зависимые переменные близко к эталону, соблюдая ограничения как для независимых, так и для зависимых переменных. MPC обычно вычисляет только первое изменение в каждой независимой переменной, и повторяет вычисление, когда требуется следующее изменение.

Многие реальные процессы нелинейны, но их можно считать линейными на маленьком рабочем диапазоне. Линейный подход используется в большиснтве приложений с механизмом обратной связи MPC, компенсирующим ошибки прогнозирования из-за структурного несоответствия между моделью и процессом. В управлениях, которые состоят только из линейных моделей, принцип суперпозиции линейной алгебры позволяет суммировать эффект изменений нескольких независимых переменных для прогнозирования реакции зависимых переменных. Это упрощает задачу управления до ряда прямых матричных вычислений, которые быстры и безошибочны. Когда линейные модели недостаточно точны для представления реальных нелинейных процессов, можно использовать несколько подходов. В некоторых случаях переменные процесса могут быть преобразованы до и / или после линейной модели MPC, чтобы уменьшить нелинейность. Процесс может контролироваться с помощью нелинейного MPC, который использует нелинейную модель непосредственно в приложении управления. Нелинейная модель может быть в форме эмпирического подбора данных (например, искусственных нейронных сетей) или динамической модели высокой точности, основанной на фундаментальных балансах массы и энергии.

MPC основан на пошаговой оптимизации модели с конечным шагом/горизонтом???  В момент времени  t замеряется текущее состояние? и вычисляется стратегия управления с минимальными затратами (с помощью алгоритма численной минимизации) для относительно короткого горизонта в будущем: [t, t + T]. В частности, онлайн-вычисления или вычисления «на лету» используются для изучения траекторий состояния, которые исходят из текущего состояния, и находят (посредством решения уравнений Эйлера – Лагранжа) стратегию с минимальными затратами до времени  $ t + T$. Реализуется только первый шаг стратегии управления, затем снова производится измерение состояния, и вычисления повторяются, начиная с нового текущего состояния. Получается новый элемент управления и новый прогнозируемая траектория состояния. Горизонт прогнозирования продолжает смещаться вперед, и по этой причине MPC также называют управлением по смещаемому горизонту.

MPC --- многомерный алгоритм управления, который использует:
\begin{itemize}
  \item Внутренняя динамическая модель процесса.
 \item Функция затрат J над смещаемым горизонтом.
  \item Оптимизационный алгоритм минимизирующий функцию стоимости J используя управляющее воздействие.
\end{itemize}


В западной литературе управление в реальном времени представлено теорией управления по прогнозирующей модели --- Model Predictive Control (MPC), также называемая Receding Horizon Control (RHC). Основными приложениями теории являются задачи стабилизации динамических систем. Современная теория нелинейного MPC предлагает основанные на решении задач оптимального управления методы построения обратных связей для нелинейных объектов.


\paragraph{Нелинейное управление по прогнозирующей модели}
Нелинейное управление по прогнозирующей модели — это оптимизационный метод для управления по обратной связи нелинейных систем. Его основные приложения — это [стабилизационная задача и задача отслеживания?? stabilization and tracking problems].
Предположим, что нам дан контролируемый процесс, состояние которого x(n) измеряется в дискретные моменты времени $t_n$ $n=0, 1 \dots$
«Контролируемый» означает, что в каждый момент времени мы можем выбрать управляющее воздействие u(n), которое влияет на будущее поведение состояния системы. В [следящем?? tracking] управлении задача состоит в том, чтобы определить управляющее воздействие u(n) таким образом, чтобы x(n) следовало заданному эталону $x^{ref}(n)$ настолько точно, насколько это возможно. Это значит, что если текущее состояние далеко от эталонного, то мы должны управлять системой в направлении эталонного состояния, а если текущее состояние уже близко к эталону, то мы стараемся удержать его там. Для простоты будем считать, $x(n)\in  X = R^d$ и $u(n)\in U = R^m$, более того считаем эталон константой и равным $x_*= 0$, т.е, $x^{ref}(n) = x_* = 0$ для всех $n \geqslant 0$. С таким константным эталоном задача отслеживания упрощается до задачи стабилизации.
Так как мы хотим иметь возможность влиять на отклонение x(n) от эталонного значения $x_* = 0$, нам бы хотелось иметь u(n) в [обратном? feedback] виде, т.е. в виде $u(n) =\mu(x(n))$, где некоторое отображение ? отображает состояние $x \in X$ во множество значений управления U.
Идея управления по прогнозирующей модели — как использовать модель процесса с целью предсказания и оптимизации будущего поведения системы. Будем рассматривать модели вида
$x^+ = f (x, u)$                                                                                                        (1.1)
 где $f: X \times U \to X$ это известная, вообще говоря, нелинейная функция, которая ставит в соответствие состоянию x и значению управления u [последовательное значение? successor state] $x^+$ в следующий момент времени. Начиная с текущего состояния x(n), для любой последовательности управлений $u(0), \dots , u(N -1)$ с длиной горизонта $N \geqslant 2$, мы можем совершать итерации (1.1) с целью составления прогнозируемой траектории $x_u$ определённой как
$x_u(0) = x(n)$, $x_u(k + 1) = f (x_u(k), u(k)), k = 0, \dots , N - 1$                                                        (1.2)
Этим способом мы получаем прогнозы $x_u(k)$ для состояния системы x(n+k) в момент времени $t_{n+k}$ в будущем. Таким образом, мы получаем прогноз поведения системы на дискретном интервале $t_n, \dots , t_{n+N}$ в зависимости от выбранной последовательности управлений $u(0), \dots , u(N - 1)$.
Теперь мы используем оптимальное управление для определения $u(0), \dots , u(N - 1)$ таким образом, чтобы $x_u$ было как можно ближе к $x_* = 0$. С этой целью мы измеряем расстояние между $x_u(k)$ и $x_* = 0$ для $k = 0, \dots , N - 1$ с помощью функции  $\ell(x_u(k), u(k))$. То есть мы не только вводим штраф за отклонение состояния от эталона, но также – если хотим – расстояние значений управления u(k) до эталонного управления $u_*$, которое мы здесь также выбираем $u_*$=0. Стандартныйи популярный выбор для этой цели – это квадратичная функция
$\ell(x_u(k), u(k)) =  ||xu(k)||^2 + \lambda||u(k)||^2$
где || . || обозначает обычную Евклидову норму, а $\lambda \geqslant 0$ это весовой параметр управления, который также может быть принят равным 0, если мы желаем вводить штраф. Теперь задача оптимального управления выглядит так:

minimize $J(x(n),u(.)):= \sum_{k=0}^{N-1}\ell(x_u(k), u(k))$

Для всех допустимых последовательностей управления $u(0), \dots, u(N - 1)$ с $x_u$ вычисленными по формулам (1.2).
Будем считать, что ЗОУ имеет решение, которое получается в результате минимизации последовательности управлений u*(0), \dots , u*(N - 1), то есть

$\min J(x(n),u(.)) =  \sum_{k=0}^{N-1}\ell(x_{u^*}(k), u^*(k))$


 Чтобы получить желаемое значение величины обратной связи $\mu(x(n))$, мы теперь устанавливаем $\mu(x(n)):= u^*(0)$, то есть, мы используем первый элемент последовательности оптимальных управлений.
В следующие моменты времени $t_{n+1}, t_{n+2}, \dots$ мы повторяем процедуру с новыми измерениями $x(n + 1), x(n + 2), \dots$ с целью получения переменных обратной связи $\mu(x(n + 1)), \mu(x(n + 2)), \dots $ Другими словами, мы получаем закон обратной связи $\mu$ с помощью итерационной онлайн оптимизации над прогнозами, полученными с помощью нашей модели (1.1). Это первая ключевая характеристика управления по прогнозирующей модели.


С точки зрения горизонта планирования, при выполнение этих итераций, траектории $x_u (k), k = 0,\dots N$ обеспечивают прогноз на дискретном интервале $t_n,\dots t_{n + N}$ в момент времени $t_n$, на интервале $t_{n + 1},\dots t_{n + N + 1}$ в момент времени $t_{n + 1}$, на интервале $t_{n + 2},\dots t_{n+N+2}$ в момент времени $t_{n + 2}$ и т. д. Следовательно, горизонт планирования движется, и этот движущийся горизонт является второй ключевой характеристикой управления по прогнозирующей модели.

\section{Экономический MPC}\label{1sec:EMPC}
Экономический MPC это вид MPC, в котором, в отличие от обычного, задача управления не обязательно связана со стабилизацией априори заданной точки [значения?] (или траектории), а с оптимизацией некоторого общего критерия эффективности, возможно относящегося к экономике рассматриваемой системы. В связи с использованием общего критерия эффективности оптимальный режим работы рассматриваемой системы может быть не стационарным, а циклическим или даже более сложным. Отсюда возникает вопрос, как узнать, каков оптимальный режим работы данной системы и данной функции стоимости. Более того, желательно гарантировать, чтобы замкнутая система [система с обратной связью???] возникающая в результате применения схемы экономического MPC, «находила» оптимальное рабочее поведение, то есть сходилась к оптимальной траектории.
\section{Задачи оптимального управления}\label{1sec:ZOU}
Задачи оптимального управления относятся к теории экстремальных задач, то есть задач определения максимальных и минимальных значений.
Постановка любой конкретной задачи оптимального управления включает в себя ряд факторов: математическую модель управляемого объекта, цель управления (именуемую иногда критерием качества), различного рода ограничения на траекторию системы, управляющее воздействие, длительность процесса управления, класс допустимых управлений и т.д.


\subsection{Постановка задач оптимального управления}\label{1sec:qwerty}
\subsubsection{Модели объекта}

В зависимости от вида рассматриваемого явления и желаемой степени детализации его изучения могут быть использованы различные типы уравнений: обыкновенные дифференциальные уравнения, уравнения с последействием, стохастические уравнения, уравнения в частных производных и т.д. Предположим ради определенности, что эволюция объекта описывается системой обыкновенных дифференциальных уравнений.
%\begin{flushright}
%	\normalsize{ $\dot x(t) = f(t,x(t),u),\dot x(t)=dx\dt, t_0 \le t \le T $ \hspace{4cm} (1)}
%\end{flushright}

$\dot x(t)= f(t,x(t),u), \dot x(t)= \frac {dx} {dt}, t_0 \le t \le T$ \hspace{4cm} (1)

Здесь $u \in R^m$ --- управление,$x \in R^n$ --- фазовый вектор системы, $f \in R^n$--- заданная функция, $R^n$---евклидово пространство размености n. Придавая управлению u различные возможные значения, получаем различные состояния объекта, среди которых выбирается оптимальное.

\subsubsection{Критерий качества}

Управление системой (1) осуществляется для достижения некоторых целей, которые формально записываются в терминах минимизации по u функционалов J, определяемых управлением u и траекторией х, где
$J= \int_{t_0}^{T}(F(t,x(t),u)dt)+ \varphi (T,x(T)) \to min$\hspace{5cm}(2)

Здесь F и $\varphi$ – заданные скалярные функции. Задача (1), (2) в общем виде называется задачей Больца. Если $F$ = 0, то её называют задачей Майера, а если $\varphi$ = 0, то это задача Лагранджа.
\subsubsection{Ограничения на траекторию}

Иногда в реальных ситуациях траектория не может принадлежать какой-либо части пространства $R^n$. Тогда указывают, что $x(t) \in G(t)$, где $G(t)$-заданная область в $R^n$. В зависимости от типа ограничений выделяют различные классы задач управления. В задачах с фиксированными концами начальное состояние $x(t_0)$ и конечное состояние $x(T)$ заданы. Если $x(t_0) (x(T))$ не задано, то получаем задачу со свободным левым(правым) концом. Также ограничения могут быть интегрального характера:
$\int_{t_0}^{T}F(t,x(t),u)dt \le 0$

Если в задаче (1),(2) начальное и конечное положение задано, моменты начала и конца движения свободны, функция $\varphi = 0$, а $F = 1$, то получаем задачу оптимального быстродействия.

\subsubsection{Ограничения на управление}

Ограничения на управление зависят от того, какая информация о системе (1) доступна в момент выработки управляющего воздействия. Если x(t) недоступен, то оптимальное управление ищется в классе функций u(t), зависящих только от t. Тогда оптимальное управление называется программным. Если x(t) известен при $t_0 \le t \le T$, то оптимальное управление ищется в классе функционалов $u(t,x_{t_0}^t)$ и называется управлением по обратной связи. $x_{t_0}^t$ означает всю траекторию движения на отрезке $t_0 \le s \le T$

\subsection{Условия оптимальности, принцип максимума}\label{1sec:qwerty1}


Сформулируем необходимые условия оптимальности в форме принципа максимума для задачи Майера

$\dot x(t)= f(t,x(t),u), t_0 \le t \le T, x(t_0)=x_0,$

$u(t) \in U, J=F(x(t)) \to min$ \hspace{6cm}(3)

$U \subset R^m$ --- заданное множество, $x_0$ --- заданное начальное положение системы. Введём в рассмотрение скалярную функцию H и вектор сопряжённых переменных $\psi \in R^n$ с помощью соотношений

$ H(t, x(t), u(t), \psi(t))=\psi'(t)f(t,x(t),u(t)),$

$\dot \psi(t)=-\frac{\partial H}{\partial x}(t, x(t), u(t), \psi(t)),$ \hspace{3cm}(4)

$\psi(T)=-\frac{\partial F(x(t))}{\partial x}$,

где ' --- знак транспонирования.

Предположим, что $u(t)$ --- оптимальное управление, а $x(t) и \psi(t)$ --- соответствующие траектория и вектор сопряжённых переменных, удовлетворяющие уравнениям (3) (4). Тогда функция $H(t, x(t), u, \psi(t))$ достигает своего максимума по $u\in U$ в точке u(t)

$H(t, x(t), u(t), \psi(t))= \max_{u \in U}(t, x(t), u, \psi(t))$. \hspace{4cm} (5)

Из (5) найдём зависимость u от $t, \psi, x,$ то есть

$u=u(t,x(t), \psi (t))$ \hspace{5cm} (6)

Далее подставим (6) в (3) и (4). В результате получим краевую задачу для системы обыкновенных дифференциальных уравнений относительно $ x(t)$ и $\psi(t)$. Только среди её решений может находиться оптимальная траектория. Если $x(t)$ и $\psi(t)$ найдены, то оптимальное управление находится из (6). Однако не стоит забывать, что (3)-(5) являются необходимыми условиями оптимальности, а значит, необходимо дополнительно подтвердить, что найденные траектории и управление являются оптимальными

\section{Численные методы решения задач оптимального управления и программные средства}\label{1sec:Zou}
\subsection{Численные методы решения задач оптимального управления}\label{1sec:zou}
Рассмотрим некоторые методы решения задач оптимального управления.
\subsubsection{Метод штрафных функций}
\paragraph{Изложение метода}
Основная задача метода штрафных функций состоит в преобразовании задачи минимизации функции $z=f(x)$ с соответствующими ограничениями, наложенными на х, в задачу поиска минимума без ограничений функции  $Z=f(x)+P(x)$. Функция $P(x)$ является штрафной. Необходимо, чтобы при нарушении ограничений она «штрафовала» функцию Z, т.е. увеличивала её значение.В этом случае минимум функции Z будет находиться внутри области ограничений. Функция P(x), удовлетворяющая этому условию, может быть не единственной. Задачу минимизации можно сформулировать следующим образом:

минимизировать функцию $z=f(x)$ при ограничениях $c_j(x), j=1, 2, \dots, m$.

Функцию P(x) удобно записать следующим образом: $P(x)=r \sum_{j=1}^{m}\frac{1}{c_j(x)}$, где r – положительная величина. Тогда функция $Z=\varphi(x,r)$ принимает вид $Z=\varphi(x,r)=f(x)+r \sum_{j=1}^{m}\frac{1}{c_j(x)}$

Если х принимает допустимые значения, т.е. значения, для которых $c_j \geq 0$ , то Z принимает значения, которые больше соответствующих значений f(x) (истинной целевой функции данной задачи), и разность можно уменьшить за счет того, что r может быть очень малой величиной. Но если х принимает значения, которые хотя и являются допустимыми, но близки к границе области ограничений, и по крайней мере одна из функций $c_j(x)$ близка к нулю, тогда значения функции P(x), и следовательно значения функции Z станут очень велики. Таким образом, влияние функции P(x) состоит в создании «гребня с крутыми краями» вдоль каждой границы области ограничений. Следовательно, если поиск начнется из допустимой точки и осуществляется поиск минимума функции $\varphi(x,r)$ без ограничений, то минимум, конечно, будет достигаться внутри допустимой области для задачи с ограничениями. Полагая r достаточно малой величиной, для того чтобы влияние P(x) было малым в точке минимума, мы можем сделать точку минимума функции $\varphi(x,r)$ без ограничений совпадающей с точкой минимума задачи с ограничениями.

\paragraph{Алгоритм метода штрафных функций}
Пусть имеется следующая задача: Минимизировать f(x) при ограничениях $g_i(x) \geq 0 i=\overline{1,m}$
\subparagraph{Начальный этап}
Выбрать $\epsilon \ge 0$ в качестве константы остановки, начальную допустимую точку $x^0 \in R^n$, для которой $g_i(x^0) \ge 0, i=\overline{1,m}$, скаляр $r_0$ и $0 \le \beta \le 1$. Положить k=1 и перейти к основному этапу.
\subparagraph{Основной этап}
 При исходной точке $x_k$ решить следующую задачу безусловной оптимизации:
$ P(x,r)=f(x)+r\sum_{i=1}^mR_i(g_i(x))\omega_i$ минимизировать, где

$r\ge 0$ - параметр, значения которого убывают с каждой итерации $R_i(t) \to \infty $ при $t \to 0; \omega_i$ - положительные весовые коэффициенты.

Примерами штрафных функций являются:
\begin{itemize}
  \item обратная функция$ R_i(g_i(x))=\frac{1}{g_i(x)}$

  \item логарифмическая функция $R_i(g_i(x))=-ln(g_i(x))$
\end{itemize}



Положить $x_{k+1}$ равным оптимальному решению задачи минимизации и перейти ко второму шагу.

Минимизация штрафной функцию может быть выполнена любым методом безусловной оптимизации, например, градиентным.

Если $r_k\sum R(g_i(x_{k+1}))\omega_i<\epsilon$, то остановиться. Решение является искомым.

В противном случае положить $r_{k+1}=\beta r_k$. Изменить k=k+1 и перейти к первому шагу (k+1)-й итерации.

\subsubsection{Метод сопряжённых градиентов}

Метод сопряжённых градиентов — итерационный метод для безусловной оптимизации в многомерном пространстве. Основным достоинством метода является то, что он решает квадратичную задачу оптимизации за конечное число шагов. Поэтому, сначала описывается метод сопряжённых градиентов для оптимизации квадратичного функционала, выводятся итерационные формулы, приводятся оценки скорости сходимости. После этого показывается, как метод сопряжённых обобщается для оптимизации произвольного функционала, рассматриваются различные варианты метода, обсуждается сходимость.

\paragraph{Постановка задачи оптимизации}

Пусть задано множество  $X \subset R^n$  и на этом множестве определена целевая функция (objective function) $f \: R^n \mapsto R$. Задача оптимизации состоит в нахождении на множестве X точной верхней или точной нижней грани целевой функции.
Множество точек, на которых достигается нижняя грань целевой функции обозначается $X_*$ .
%$X_* = {x \in X| f(x) = inf \limits_{x \in X} f(x) }$
Если  $X = R^n$ , то задача оптимизации называется безусловной. Если  $X \neq R^n $, то задача оптимизации называется условной.

 \paragraph{Будем решать задачу:}

$F(x) \to min, \quad x \in R^n $.
F(x)  - непрерывно дифференцируемая в $R^n$  функция. Чтобы модифицировать метод сопряжённых градиентов для решения этой задачи необходимо получить для $p_k, \alpha_k, \beta_k$  формулы, в которые не входит матрица А:

$\alpha_k =argmin\lim_{\alpha_k} F(x_{k-1} + \alpha_k  p_k)$
 $p_{k+1} = - F'(x_{k}) + \beta_{k} p_{k}$
 $\beta_k$  можно вычислять по одной из трёх формул:
 \begin{itemize}
   \item $\beta_k = - \frac{\langle F'(x_{k} ), F'(x_{k}) \rangle}{\langle F'(x_{k-1}), F'(x_{k-1}) \rangle} $ - Метод Флетчера - Ривса.
   \item $\beta_k = \frac{\langle F'(x_{k}), F'(x_k) - F'(x_{k-1} ) \rangle}{\langle F'(x_{k - 1}), F'(x_{k - 1}) \rangle}$  - Метод Полака - Райбера.
   \item $\beta_k = \frac{\langle F''(x_k) p_k, F'(x_k) \rangle}{\langle F''(x_{k - 1})p_k, p_k \rangle}$
 \end{itemize}



Если функция F(x) - квадратичная и строго выпуклая, то все три формулы дают одинаковый результат. Если F(x) - произвольная функция, то каждой из формул cоответствует своя модификация метода сопряжённых градиентов. Третья формула используется редко, так как она требует, чтобы функция $F(x) \in C^2(R^n)$ и вычисления гессиана функции F(x) на каждом шаге метода.
\subparagraph{Анализ метода}
Если функция F(x) - не квадратичная, метод сопряжённых градиентов может и не сходиться за конечное число шагов. Кроме того, точное вычисление $\alpha_k$ на каждом шаге возможно только в редких случаях. Поэтому накопление погрешностей приводит к тому, что вектора  $p_k $ перестают указывать направление убывания функции F(x). Тогда на каком-то шаге полагают $\beta_k = 0$. Совокупность всех номеров k, при которых принимается $\beta_k = 0$, обозначим за $I_0$. Номера $k \in I_0 $ называются моментами обновления метода. На практике часто выбирают $I_0 = \{n, 2n, 3n, \dots \}$, где n - размерность пространства.

\subparagraph{Сходимость метода}
Для метода Флетчера - Ривса существует теорема о сходимости, накладывающая не слишком жёсткие условия на минимизируемую функцию F(x):
Теорема.

Пусть  $F(x) \in C^1(R^n)$ и выполняются следующие условия:

 $\alpha_k$  удовлетворяет строгим условиям Вольфа:
 $F(x_{k -1} + \alpha_k p_k ) \leq F(x_{k - 1}) +  c_1 \alpha_k \langle F'(x_{k - 1}), p_k \rangle | \langle F'(x_{k -1} + \alpha_k p_k), p_k \rangle  \leq c_2 |\langle F'(x_{k - 1}), p_k \rangle|$ где  $0 < c_1 < c_2 < 1/2$
Множество  $M = \{ x | F(x) \leq F(x_0) \}$ ограничено
Производная F'(x) удовлетворяет условию Липшица с константой L в некоторой окрестности  N
множества $M: ||F'(x_1) - F'(x_2)|| \leq L ||x_1 - x_2|| \qquad \forall x_1, x_2 \in N $.
Тогда
 $\lim \limits_{k \to \infty} inf ||F'(x_k)| = 0$
Для метода Полака-Райбера доказана сходимость в предположении, что F(x) - строго выпуклая функция. В общем случае доказать сходимость метода Полака - Райбера невозможно. Напоротив, верна следующая теорема:

Предположим, что в методе Полака-Райбера значения $\alpha_k$ на каждом шаге вычисляются точно. Тогда существует функция $F : R^3 \mapsto R, \quad F(x) \in C^2(R^3)$, и начальное приближение $x_0$ , такие что $\exists \delta > 0, \forall k = 0, 1, 2, ... \quad ||f(x_k)|| > \delta$.

Тем не менее, на практике метод Полака-Райбера работает лучше.
Наиболее распространённые критерии останова на практике: Норма градиента становится меньше некоторого порога
Значение функции в течении m последовательных итераций почти не изменилось 