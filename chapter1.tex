\chapter{ОСНОВНЫЕ ПОНЯТИЯ И ОБЗОР ЛИТЕРАТУРЫ }\label{chap1}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Теория управления по прогнозирующей модели}\label{1sec:MPC}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Управление по прогнозирующей модели(MPC)- это продвинутый метод управления, который используется для управления процессом  при одновременном удовлетворении набора ограничений.Он используется в перерабатывающей промышленности на химических и нефтеперерабатывающих заводах с 1980-х годов. В последние годы он также используется в моделях балансировки энергосистем и в силовой электронике. Прогнозирующие контроллеры моделей опираются на динамические модели процесса. Основным преимуществом MPC является тот факт, что он позволяет оптимизировать текущий временной интервал, сохраняя при этом будущие временные интервалы в учете. Это достигается за счет оптимизации конечного временного горизонта, но только реализации текущего временного интервала и последующей повторной оптимизации. Модели используемые в MPC обычно призваны показать поведение сложных динамических систем. Модели MPC предсказывают изменение в зависимых переменных моделируемой системы, которое будет вызвано изменениями в независимых переменных.Независимые переменные, которые не могут быть [скорректированы? связаны с? управлением], воспринимаются как возмущения. Зависимыми переменными в этих процессах представляют  либо задачи управления, либо ограничения на процесс.
MPC использует текущие значения переменных, текущее динамическое состояние процесса, модели MPC, а также значение эталона? и ограничения переменных для расчета будущих изменений зависимых переменных. Эти изменения рассчитаны так, чтобы держать зависимые переменные близко к эталону, соблюдая ограничения как для независимых, так и для зависимых переменных. MPC обычно вычисляет только первое изменение в каждой независимой переменной, и повторяет вычисление, когда требуется следующее изменение.

Многие реальные процессы нелинейны, но их можно считать линейными на маленьком рабочем диапазоне. Линейный подход используется в большиснтве приложений с механизмом обратной связи MPC, компенсирующим ошибки прогнозирования из-за структурного несоответствия между моделью и процессом. В управлениях, которые состоят только из линейных моделей, принцип суперпозиции линейной алгебры позволяет суммировать эффект изменений нескольких независимых переменных для прогнозирования реакции зависимых переменных. Это упрощает задачу управления до ряда прямых матричных вычислений, которые быстры и безошибочны. Когда линейные модели недостаточно точны для представления реальных нелинейных процессов, можно использовать несколько подходов. В некоторых случаях переменные процесса могут быть преобразованы до и / или после линейной модели MPC, чтобы уменьшить нелинейность. Процесс может контролироваться с помощью нелинейного MPC, который использует нелинейную модель непосредственно в приложении управления. Нелинейная модель может быть в форме эмпирического подбора данных (например, искусственных нейронных сетей) или динамической модели высокой точности, основанной на фундаментальных балансах массы и энергии.

MPC основан на пошаговой оптимизации модели с конечным шагом/горизонтом???  В момент времени  t замеряется текущее состояние? и вычисляется стратегия управления с минимальными затратами (с помощью алгоритма численной минимизации) для относительно короткого горизонта в будущем: [t, t + T]. В частности, онлайн-вычисления или вычисления «на лету» используются для изучения траекторий состояния, которые исходят из текущего состояния, и находят (посредством решения уравнений Эйлера – Лагранжа) стратегию с минимальными затратами до времени  $ t + T$. Реализуется только первый шаг стратегии управления, затем снова производится измерение состояния, и вычисления повторяются, начиная с нового текущего состояния. Получается новый элемент управления и новый прогнозируемая траектория состояния. Горизонт прогнозирования продолжает смещаться вперед, и по этой причине MPC также называют управлением по смещаемому горизонту.

MPC --- многомерный алгоритм управления, который использует:
\begin{itemize}
  \item Внутренняя динамическая модель процесса.
 \item Функция затрат J над смещаемым горизонтом.
  \item Оптимизационный алгоритм минимизирующий функцию стоимости J используя управляющее воздействие.
\end{itemize}





В западной литературе управление в реальном времени представлено теорией управления по прогнозирующей модели --- Model Predictive Control (MPC), также называемая Receding Horizon Control (RHC). Основными приложениями теории являются задачи стабилизации динамических систем. Современная теория нелинейного MPC предлагает основанные на решении задач оптимального управления методы построения обратных связей для нелинейных объектов.

Главная идея MPC --- использование математической модели управляемого процесса в пространстве состояний для предсказания и оптимизации будущего поведения системы. Поясним на примере модели нелинейного процесса управления
\begin{equation}\label{sys2}
    \dot x = f(x,u)
    \end{equation}
где $x=x(t)\in \mathbb{R}^n$ --- состояние модели  в момент времени $t$; $u=u(t)\in
\mathbb{R}^r$ --- значение управляющего воздействия; $f:\mathbb{R}^n \to \mathbb{R}^r$ --- заданная функция, обеспечивающая существование и единственность решения (\ref{sys2}) при любом допустимом управляющем воздействии.

Нелинейное управление по прогнозирующей модели
Нелинейное управление по прогнозирующей модели — это оптимизационный метод для управления по обратной связи нелинейных систем. Его основные приложения — это [стабилизационная задача и задача отслеживания?? stabilization and tracking problems].
Предположим, что нам дан контролируемый процесс, состояние которого x(n) измеряется в дискретные моменты времени $t_n$ $n=0, 1 \dots$
«Контролируемый» означает, что в каждый момент времени мы можем выбрать управляющее воздействие u(n), которое влияет на будущее поведение состояния системы. В [следящем?? tracking] управлении задача состоит в том, чтобы определить управляющее воздействие u(n) таким образом, чтобы x(n) следовало заданному эталону $x^{ref}(n)$ настолько точно, насколько это возможно. Это значит, что если текущее состояние далеко от эталонного, то мы должны управлять системой в направлении эталонного состояния, а если текущее состояние уже близко к эталону, то мы стараемся удержать его там. Для простоты будем считать, $x(n)\in  X = R^d$ и $u(n)\in U = R^m$, более того считаем эталон константой и равным $x_*= 0$, т.е, $x^{ref}(n) = x_* = 0$ для всех $n \geqslant 0$. С таким константным эталоном задача отслеживания упрощается до задачи стабилизации.
Так как мы хотим иметь возможность влиять на отклонение x(n) от эталонного значения $x_* = 0$, нам бы хотелось иметь u(n) в [обратном? feedback] виде, т.е. в виде $u(n) =\mu(x(n))$, где некоторое отображение ? отображает состояние $x \in X$ во множество значений управления U.
Идея управления по прогнозирующей модели — как использовать модель процесса с целью предсказания и оптимизации будущего поведения системы. Будем рассматривать модели вида
$x^+ = f (x, u)$                                                                                                        (1.1)
 где $f: X \times U \to X$ это известная, вообще говоря, нелинейная функция, которая ставит в соответствие состоянию x и значению управления u [последовательное значение? successor state] $x^+$ в следующий момент времени. Начиная с текущего состояния x(n), для любой последовательности управлений $u(0), \dots , u(N -1)$ с длиной горизонта $N \geqslant 2$, мы можем совершать итерации (1.1) с целью составления прогнозируемой траектории $x_u$ определённой как
$x_u(0) = x(n)$, $x_u(k + 1) = f (x_u(k), u(k)), k = 0, \dots , N - 1$                                                        (1.2)
Этим способом мы получаем прогнозы $x_u(k)$ для состояния системы x(n+k) в момент времени $t_{n+k}$ в будущем. Таким образом, мы получаем прогноз поведения системы на дискретном интервале $t_n, \dots , t_{n+N}$ в зависимости от выбранной последовательности управлений $u(0), \dots , u(N - 1)$.
Теперь мы используем оптимальное управление для определения $u(0), \dots , u(N - 1)$ таким образом, чтобы $x_u$ было как можно ближе к $x_* = 0$. С этой целью мы измеряем расстояние между $x_u(k)$ и $x_* = 0$ для $k = 0, \dots , N - 1$ с помощью функции  $\ell(x_u(k), u(k))$. То есть мы не только вводим штраф за отклонение состояния от эталона, но также – если хотим – расстояние значений управления u(k) до эталонного управления $u_*$, которое мы здесь также выбираем $u_*$=0. Стандартныйи популярный выбор для этой цели – это квадратичная функция
$\ell(x_u(k), u(k)) =  ||xu(k)||^2 + \lambda||u(k)||^2$
где || . || обозначает обычную Евклидову норму, а $\lambda \geqslant 0$ это весовой параметр управления, который также может быть принят равным 0, если мы желаем вводить штраф. Теперь задача оптимального управления выглядит так:

minimize $J(x(n),u(.)):= \sum_{k=0}^{N-1}\ell(x_u(k), u(k))$

Для всех допустимых последовательностей управления $u(0), \dots, u(N - 1)$ с $x_u$ вычисленными по формулам (1.2).
Будем считать, что ЗОУ имеет решение, которое получается в результате минимизации последовательности управлений u*(0), \dots , u*(N - 1), то есть

$\min J(x(n),u(.)) =  \sum_{k=0}^{N-1}\ell(x_{u^*}(k), u^*(k))$


 Чтобы получить желаемое значение величины обратной связи $\mu(x(n))$, мы теперь устанавливаем $\mu(x(n)):= u^*(0)$, то есть, мы используем первый элемент последовательности оптимальных управлений.
В следующие моменты времени $t_{n+1}, t_{n+2}, \dots$ мы повторяем процедуру с новыми измерениями $x(n + 1), x(n + 2), \dots$ с целью получения переменных обратной связи $\mu(x(n + 1)), \mu(x(n + 2)), \dots $ Другими словами, мы получаем закон обратной связи $\mu$ с помощью итерационной онлайн оптимизации над прогнозами, полученными с помощью нашей модели (1.1). Это первая ключевая характеристика управления по прогнозирующей модели.


С точки зрения горизонта планирования, при выполнение этих итераций, траектории $x_u (k), k = 0,\dots N$ обеспечивают прогноз на дискретном интервале $t_n,\dots t_{n + N}$ в момент времени $t_n$, на интервале $t_{n + 1},\dots t_{n + N + 1}$ в момент времени $t_{n + 1}$, на интервале $t_{n + 2},\dots t_{n+N+2}$ в момент времени $t_{n + 2}$ и т. д. Следовательно, горизонт планирования движется, и этот движущийся горизонт является второй ключевой характеристикой управления по прогнозирующей модели.

\section{Экономический MPC}\label{1sec:EMPC}
Экономический MPC это вид MPC, в котором, в отличие от обычного, задача управления не обязательно связана со стабилизацией априори заданной точки [значения?] (или траектории), а с оптимизацией некоторого общего критерия эффективности, возможно относящегося к экономике рассматриваемой системы. В связи с использованием общего критерия эффективности оптимальный режим работы рассматриваемой системы может быть не стационарным, а циклическим или даже более сложным. Отсюда возникает вопрос, как узнать, каков оптимальный режим работы данной системы и данной функции стоимости. Более того, желательно гарантировать, чтобы замкнутая система [система с обратной связью???] возникающая в результате применения схемы экономического MPC, «находила» оптимальное рабочее поведение, то есть сходилась к оптимальной траектории.
\section{Задачи оптимального управления}\label{1sec:ZOU}
Задачи оптимального управления относятся к теории экстремальных задач, то есть задач определения максимальных и минимальных значений.
Постановка любой конкретной задачи оптимального управления включает в себя ряд факторов: математическую модель управляемого объекта, цель управления (именуемую иногда критерием качества), различного рода ограничения на траекторию системы, управляющее воздействие, длительность процесса управления, класс допустимых управлений и т.д.


\subsection{Постановка задач оптимального управления}\label{1sec:qwerty}
\subsubsection{Модели объекта}

В зависимости от вида рассматриваемого явления и желаемой степени детализации его изучения могут быть использованы различные типы уравнений: обыкновенные дифференциальные уравнения, уравнения с последействием, стохастические уравнения, уравнения в частных производных и т.д. Предположим ради определенности, что эволюция объекта описывается системой обыкновенных дифференциальных уравнений.
%\begin{flushright}
%	\normalsize{ $\dot x(t) = f(t,x(t),u),\dot x(t)=dx\dt, t_0 \le t \le T $ \hspace{4cm} (1)}
%\end{flushright}

$\dot x(t)= f(t,x(t),u), \dot x(t)= \frac {dx} {dt}, t_0 \le t \le T$ \hspace{4cm} (1)

Здесь $u \in R^m$ --- управление,$x \in R^n$ --- фазовый вектор системы, $f \in R^n$--- заданная функция, $R^n$---евклидово пространство размености n. Придавая управлению u различные возможные значения, получаем различные состояния объекта, среди которых выбирается оптимальное.

\subsubsection{Критерий качества}

Управление системой (1) осуществляется для достижения некоторых целей, которые формально записываются в терминах минимизации по u функционалов J, определяемых управлением u и траекторией х, где 
$J= \int_{t_0}^{T}(F(t,x(t),u)dt)+ \varphi (T,x(T)) \to min$\hspace{5cm}(2)

Здесь F и $\varphi$ – заданные скалярные функции. Задача (1), (2) в общем виде называется задачей Больца. Если $F$ = 0, то её называют задачей Майера, а если $\varphi$ = 0, то это задача Лагранджа.
\subsubsection{Ограничения на траекторию}

Иногда в реальных ситуациях траектория не может принадлежать какой-либо части пространства $R^n$. Тогда указывают, что $x(t) \in G(t)$, где $G(t)$-заданная область в $R^n$. В зависимости от типа ограничений выделяют различные классы задач управления. В задачах с фиксированными концами начальное состояние $x(t_0)$ и конечное состояние $x(T)$ заданы. Если $x(t_0) (x(T))$ не задано, то получаем задачу со свободным левым(правым) концом. Также ограничения могут быть интегрального характера:
$\int_{t_0}^{T}F(t,x(t),u)dt \le 0$ 

Если в задаче (1),(2) начальное и конечное положение задано, моменты начала и конца движения свободны, функция $\varphi = 0$, а $F = 1$, то получаем задачу оптимального быстродействия. 

\subsubsection{Ограничения на управление}

Ограничения на управление зависят от того, какая информация о системе (1) доступна в момент выработки управляющего воздействия. Если x(t) недоступен, то оптимальное управление ищется в классе функций u(t), зависящих только от t. Тогда оптимальное управление называется программным. Если x(t) известен при $t_0 \le t \le T$, то оптимальное управление ищется в классе функционалов $u(t,x_{t_0}^t)$ и называется управлением по обратной связи. $x_{t_0}^t$ означает всю траекторию движения на отрезке $t_0 \le s \le T$ 

\subsection{Условия оптимальности, принцип максимума}\label{1sec:qwerty1}


Сформулируем необходимые условия оптимальности в форме принципа максимума для задачи Майера

$\dot x(t)= f(t,x(t),u), t_0 \le t \le T, x(t_0)=x_0,$
 
$u(t) \in U, J=F(x(t)) \to min$ \hspace{6cm}(3)

$U \subset R^m$ --- заданное множество, $x_0$ --- заданное начальное положение системы. Введём в рассмотрение скалярную функцию H и вектор сопряжённых переменных $\psi \in R^n$ с помощью соотношений 

$ H(t, x(t), u(t), \psi(t))=\psi'(t)f(t,x(t),u(t)),$

$\dot \psi(t)=-\frac{\partial H}{\partial x}(t, x(t), u(t), \psi(t)),$ \hspace{3cm}(4)

$\psi(T)=-\frac{\partial F(x(t))}{\partial x}$, 

где ' --- знак транспонирования. 

Предположим, что $u(t)$ --- оптимальное управление, а $x(t) и \psi(t)$ --- соответствующие траектория и вектор сопряжённых переменных, удовлетворяющие уравнениям (3) (4). Тогда функция $H(t, x(t), u, \psi(t))$ достигает своего максимума по $u\in U$ в точке u(t)

$H(t, x(t), u(t), \psi(t))= \max_{u \in U}(t, x(t), u, \psi(t))$. \hspace{4cm} (5) 

Из (5) найдём зависимость u от $t, \psi, x,$ то есть

$u=u(t,x(t), \psi (t))$ \hspace{5cm} (6)

Далее подставим (6) в (3) и (4). В результате получим краевую задачу для системы обыкновенных дифференциальных уравнений относительно $ x(t)$ и $\psi(t)$. Только среди её решений может находиться оптимальная траектория. Если $x(t)$ и $\psi(t)$ найдены, то оптимальное управление находится из (6). Однако не стоит забывать, что (3)-(5) являются необходимыми условиями оптимальности, а значит, необходимо дополнительно подтвердить, что найденные траектории и управление являются оптимальными

\section{Численные методы решения задач оптимального управления и программные средства}\label{1sec:Zou} 