\chapter{ОСНОВНЫЕ ПОНЯТИЯ И ОБЗОР ЛИТЕРАТУРЫ }\label{chap1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Теория управления по прогнозирующей модели}\label{1sec:MPC}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Управление по прогнозирующей модели(MPC) --- это продвинутый метод управления, который используется для управления процессом  при одновременном удовлетворении набора ограничений. Главная идея MPC --- использование математической модели управляемого процесса в пространстве состояний для предсказания и оптимизации будущего поведения системы. Он используется в перерабатывающей промышленности на химических и нефтеперерабатывающих заводах с 1980-х годов. В последние годы он также используется в моделях балансировки энергосистем и в силовой электронике. Основным преимуществом MPC является тот факт, что он позволяет оптимизировать текущий временной интервал, учитывая при этом будущие временные интервалы. Это достигается за счет оптимизации конечного временного горизонта, но только на текущем временном интервале. Модели используемые в MPC обычно призваны показать поведение сложных динамических систем. Модели MPC предсказывают изменение в зависимых переменных моделируемой системы, которое будет вызвано изменениями в независимых переменных. Независимые переменные, которые не связаны с управлением, воспринимаются как возмущения. Зависимыми переменными в этих процессах представляют  либо задачи управления, либо ограничения на процесс.
MPC использует текущие значения переменных, текущее динамическое состояние процесса, модель, а также значение эталона (reference) и ограничения переменных для расчета будущих изменений зависимых переменных. Эти изменения рассчитаны так, чтобы держать зависимые переменные близко к эталону, соблюдая ограничения как для независимых, так и для зависимых переменных. MPC обычно вычисляет только первое изменение в каждой независимой переменной, и повторяет вычисление, когда требуется следующее изменение.

Многие реальные процессы нелинейны, но их можно считать линейными на маленьком рабочем диапазоне. Линейный подход используется в большиснтве приложений с механизмом обратной связи MPC, компенсирующим ошибки прогнозирования из-за структурного несоответствия между моделью и процессом. В управлениях, которые состоят только из линейных моделей, принцип суперпозиции линейной алгебры позволяет суммировать эффект изменений нескольких независимых переменных для прогнозирования реакции зависимых переменных. Это упрощает задачу управления до ряда прямых матричных вычислений, которые быстры и безошибочны. Когда линейные модели недостаточно точны для представления реальных нелинейных процессов, можно использовать несколько подходов. В некоторых случаях переменные процесса могут быть преобразованы до и / или после линейной модели MPC, чтобы уменьшить нелинейность. Процесс может контролироваться с помощью нелинейного MPC, который использует нелинейную модель непосредственно в приложении управления. Нелинейная модель может быть в форме эмпирического подбора данных (например, искусственных нейронных сетей) или динамической модели высокой точности, основанной на фундаментальных балансах массы и энергии.

MPC основан на пошаговой оптимизации модели с конечным горизонтом. В момент времени  $t$ замеряется текущее состояние и вычисляется стратегия управления с минимальными затратами (с помощью алгоритма численной минимизации) для относительно короткого горизонта в будущем: $[t, t + T]$. В частности, онлайн-вычисления или вычисления «на лету» используются для изучения траекторий состояния, которые исходят из текущего состояния, и находят (посредством решения уравнений Эйлера – Лагранжа) стратегию с минимальными затратами до времени  $ t + T$. Реализуется только первый шаг стратегии управления, затем снова производится измерение состояния, и вычисления повторяются, начиная с нового текущего состояния. Получается новый элемент управления и новый прогнозируемая траектория состояния. Горизонт прогнозирования продолжает смещаться вперед, и по этой причине MPC также называют управлением скользящим горизонтам.

MPC использует:
\begin{itemize}
  \item Внутренняя динамическая модель процесса.
 \item Функция затрат $J$ над горизонтом прогнозирования.
  \item Оптимизационный алгоритм минимизирующий функцию стоимости $J$ используя управляющее воздействие.
\end{itemize}


В западной литературе управление в реальном времени представлено теорией управления по прогнозирующей модели --- Model Predictive Control (MPC), также называемая Receding Horizon Control (RHC). Основными приложениями теории являются задачи стабилизации динамических систем. Современная теория нелинейного MPC предлагает основанные на решении задач оптимального управления методы построения обратных связей для нелинейных объектов.


\paragraph{Нелинейное управление по прогнозирующей модели}

Нелинейное управление по прогнозирующей модели — это оптимизационный метод для управления нелинейными системами по принципу обратной связи. Его основные приложения — это задача стабилизации и задача отслеживания (stabilization and tracking problems).

%%\includegraphics[scale=0.5]{pic2}

Предположим, что нам дан управляемый процесс, состояние которого $x(n)$ измеряется в дискретные моменты времени $t_n$, $n=0, 1 \dots$
«Управляемый» означает, что в каждый момент времени мы можем выбрать управляющее воздействие $u(n)$, которое влияет на будущее поведение состояния системы. В следящем (tracking) управлении задача состоит в том, чтобы определить управляющее воздействие $u(n)$ таким образом, чтобы $x(n)$ следовало заданному эталону $x^{ref}(n)$ настолько точно, насколько это возможно. Это значит, что если текущее состояние далеко от эталонного, то мы должны управлять системой в направлении эталонного состояния, а если текущее состояние уже близко к эталону, то мы стараемся удержать его там.

Для простоты будем считать, $x(n)\in  X = R^d$ и $u(n)\in U = R^m$, более того, считаем эталон константой и равным $x_*= 0$, т.е, $x^{ref}(n) = x_* = 0$ для всех $n \geqslant 0$. С таким константным эталоном задача отслеживания упрощается до задачи стабилизации.

Так как мы хотим иметь возможность влиять на отклонение $x(n)$ от эталонного значения $x_* = 0$, нам бы хотелось иметь $u(n)$ виде обратной связи, т.е. в виде $u(n) =\mu(x(n))$, где отображается некоторое состояние $x \in X$ во множество значений управления $U$.
Идея управления по прогнозирующей модели — как использовать модель процесса с целью предсказания и оптимизации будущего поведения системы.

Будем рассматривать модели вида

\begin{equation}\label{1}
  x^+ = f (x, u)
\end{equation}

 где $f: X \times U \to X$ это известная, вообще говоря, нелинейная функция, которая ставит в соответствие состоянию $x$ и значению управления $u$ последовательное значение (successor state) $x^+$ в следующий момент времени. Начиная с текущего состояния x(n), для любой последовательности управлений $u(0), \dots , u(N -1)$ с длиной горизонта $N \geqslant 2$, мы можем совершать итерации (\ref{1}) с целью составления прогнозируемой траектории $x_u$ определённой как

 \begin{equation}\label{2}
   x_u(0) = x(n), x_u(k + 1) = f (x_u(k), u(k)), k = 0, \dots , N - 1.
 \end{equation}

Этим способом мы получаем прогнозы $x_u(k)$ для состояния системы $x(n+k)$ в момент времени $t_{n+k}$ в будущем. Таким образом, мы получаем прогноз поведения системы на дискретном интервале $t_n, \dots , t_{n+N}$ в зависимости от выбранной последовательности управлений $u(0), \dots , u(N - 1)$.

Теперь мы используем оптимальное управление для определения $u(0), \dots , u(N - 1)$ таким образом, чтобы $x_u$ было как можно ближе к $x_* = 0$. С этой целью мы измеряем расстояние между $x_u(k)$ и $x_* = 0$ для $k = 0, \dots , N - 1$ с помощью функции  $\ell(x_u(k), u(k))$. То есть мы не только вводим штраф за отклонение состояния от эталона, но также – если хотим – расстояние значений управления $u(k)$ до эталонного управления $u_*$, которое мы здесь также выбираем $u_*$=0. Стандартныйи выбор для этой цели – это квадратичная функция
 $$\ell(x_u(k), u(k)) =  ||xu(k)||^2 + \lambda||u(k)||^2$$
где $||\cdot||$ обозначает обычную евклидову норму, а $\lambda \geqslant 0$ это весовой параметр управления, который также может быть принят равным 0, если мы желаем вводить штраф.

Теперь задача оптимального управления выглядит так:
$$minimize J(x(n),u(\cdot)):= \sum_{k=0}^{N-1}\ell(x_u(k), u(k))$$

Будем считать, что ЗОУ имеет решение, которое получается в результате минимизации последовательности управлений $u*(0), \dots , u*(N - 1)$, то есть

$$\min J(x(n),u(.)) =  \sum_{k=0}^{N-1}\ell(x_{u^*}(k), u^*(k))$$


 Чтобы получить желаемое значение величины обратной связи $\mu(x(n))$, мы теперь устанавливаем $\mu(x(n)):= u^*(0)$, то есть, мы используем первый элемент последовательности оптимальных управлений.

В следующие моменты времени $t_{n+1}, t_{n+2}, \dots$ мы повторяем процедуру с новыми измерениями $x(n + 1), x(n + 2), \dots$ с целью получения переменных обратной связи $\mu(x(n + 1)), \mu(x(n + 2)), \dots $ Другими словами, мы получаем закон обратной связи $\mu$ с помощью итерационной онлайн оптимизации над прогнозами, полученными с помощью нашей модели (1.1). Это первая ключевая характеристика управления по прогнозирующей модели.


С точки зрения горизонта планирования, при выполнение этих итераций, траектории $x_u (k), k = 0,\dots N$ обеспечивают прогноз на дискретном интервале $t_n,\dots t_{n + N}$ в момент времени $t_n$, на интервале $t_{n + 1},\dots t_{n + N + 1}$ в момент времени $t_{n + 1}$, на интервале $t_{n + 2},\dots t_{n+N+2}$ в момент времени $t_{n + 2}$ и т. д. Следовательно, горизонт планирования скользит, и этот движущийся горизонт является второй ключевой характеристикой управления по прогнозирующей модели.

\section{Экономический MPC}\label{1sec:EMPC}
Экономический MPC это вид MPC, в котором, в отличие от обычного, задача управления связана не со стабилизацией априори заданной точки (или траектории), а с оптимизацией некоторого общего критерия эффективности, относящегося к экономике рассматриваемой системы. Обычно в качестве целевой функции используется некоторая экономическая цель.

\paragraph{Предположение 1} Штрафная функция (функция цены) стандартного MPC
\begin{equation}\label{3}
  0=\ell (x_s, u_s)\le\ell (x,u) \text{ для всех допустимых } (x,u)
\end{equation}

где $\ell \colon \mathbb X \times \mathbb U \mapsto \mathbb R$, $\mathbb X$ множество допустимых состояний, а $\mathbb U$ --- множество допустимых управлений.

В EMPC издержки при управлении предприятием используется как цена этапа в целевой функции MPC. Так как издержки при управлении предприятием могут не быть нулевыми даже при оптимальных устойчивых условиях, (\ref{3}) в общем случае не верно. Более того, может так случиться, что $\ell (x_s, u_s)\ge\ell (x,u)$, для некоторой допустимой пары $(x,u)$, которая не является устойчивым состоянием.

Также определим дискретную конечномерную нелинейную систему в виде

\begin{equation}\label{4}
  x^+=f(x,u)
\end{equation}

где $x \in \mathbb X\subseteq \mathbb R^n$ --- состояние, $u\in \mathbb U \subset \mathbb R^m$ --- управление и $f\colon \mathbb X\times \mathbb U\mapsto \mathbb X$.

Целевая функция определяется таким образом:

\begin{equation}\label{5}
  \sum_{k}\ell(x(k),u(k))
\end{equation}
при этом

\begin{equation}\label{6}
  (x(k),u(k))\in \mathbb Z, k\in \mathbb R^+_0
\end{equation}
где $\mathbb Z \subseteq \mathbb X\times \mathbb U$.

 Определим стоимость с конечным горизонтом:
\begin{equation}\label{7}
  V_N(x,\textbf{u})=\sum_{k=0}^{N-1}\ell(x(k),u(k))
\end{equation}
где $\textbf{u}=[u(0),u(1),...,u(N-1)]$ и  $x(0)=x$.
Задача оптимизации с конечным горизонтом решается способом скользящего горизонта, когда используется первый элемент последовательности оптимальных управлений, ожидается следующее измерение или подсчёт, а потом задача решается ещё раз используя новое значение. Формально, в каждый момент времени $k$ решается следующая задача:

  $$\min_{\textbf{u}}V_N(x,\textbf{u})$$

\begin{equation}\label{8}
  \begin{cases}
    x^+=f(x,u),  \\
    (x(k),u(k))\in \mathbb Z k\in {0,1,\dots,N-1},  \\
    x(N)=x_s,x(0)=x.
  \end{cases}
\end{equation}
где мы добавили краевую константу $x(N)=x_s$. Далее определяем множество $\mathbb Z_N$ как множество (x,\textbf{u}) пар, удовлетворяющих ограничениям:

 $$ \mathbb Z_N=\{(x,\textbf{u})| \exists x(1),\dots,x(N):x^+=f(x,u),$$
  \begin{equation}\label{9}
  (x(k),u(k))\in \mathbb Z,\forall k\in {0,1,\dots,N-1},x(N)=x_s,x(0)=x\}
\end{equation}

После этого определяем множество допустимых состояний $\mathscr X_N$ как проекцию $\mathbb Z_N$ на $\mathbb X$
\begin{equation}\label{10}
  \mathscr X_N=\{x\in\mathbb X |\exists \textbf{u}:(x,\textbf{u})\in\mathbb Z_N\}
\end{equation}

Последовательность управлений   $\textbf{u} = {u(0),u(1),...u(N-1)}$ называется допустимой, для начального состояния $x$ если $(x,u)\in \mathbb Z_N$.

Формально определим оптимальное устойчивое состояние как пару $(x_s,u_s)$, которая удовлетворяет

\begin{equation}\label{11}
  \ell(x_s,u_s)=min_{x,u}\{\ell(x,u)|(x,u)\in \mathbb Z,x=f(x,u)\}
\end{equation}

Строго говоря, (\ref{11}) может состоять более чем из одной пары, но для простоты считаем, что эта пара уникальна. Оптимизационная задача (1.8) определяет неявный закон обратной связи $\mathcal{K}_N\colon \mathscr X_N\mapsto\mathbb U$ который мы обозначаем как

\begin{equation}\label{12}
  u=\mathcal{K}_N=u^0(0;x) x\in \mathscr X_N
\end{equation}
где $\textbf u^0(x)$ --- оптимальное решение (1.8) для начального состояния $x$, и $ u^0(k;x)$ обозначает оптимльное решение в момент времени $k\in {0,1,\dots,N-1}$. Без ограничения общности полагаем, что $\textbf{u}^0(x)$ однозначно определено.
\paragraph{Предположение 2}
\begin{enumerate}
  \item $f(\cdot)$ и $\ell(\cdot)$ непрерывны. Множество $\mathscr X_N$ состоит из $x_s$
  \item Существует $\gamma\colon\mathbb R^n\mapsto\mathbb R_{\ge0}$ такая, что для каждого $x\in \mathscr X_N$ существует допустимое $\textbf{u}$ с
      \begin{center}
        $|\textbf{u}-[u_s,\dots,u_s]^T|\le\gamma(|x-x_s|)$.
      \end{center}
\end{enumerate}

Установив экономическую основу мы можем рассмотреть интересную особенность EMPC:
\paragraph{Теорема} Пусть $x(0)\in \mathscr X_N$. Тогда существует по меньшей мере одна допустимая последовательность управлений, которая приводит систему в состояние $x_s$ за время $N$ оставаясь в пределах $\mathscr X_N$ и замкнутой системы (\ref{4}) и (\ref{12}) имеет асимптотическую среднюю эффективность не хуже, чем у лучшего устойчевого состояния.

\section{Задачи оптимального управления}\label{1sec:ZOU}
Задача оптимального управления --- это задача отыскания наилучшего способа управления динамическим объектом.

Математическая модель объекта управления.

\begin{equation*}
  \dot x=f(x,u,t).
\end{equation*}
где $x=x(t) \in \mathbb R^n$ --- состояние, $u=u(t)\in \mathbb R^r$ --- управление, $t$ --- время.

Управления $u$ бывают
\begin{enumerate}
  \item Кусочно-непрерывные
  \item дискретные
  \item инерционные
  \item релейные
  \item $\dots$
\end{enumerate}

Кусочно-непрерывная функция $u(t), t\in[t_0, t_f]$, которая удовлетворяет ограничению $u(t)\in U(t), t\in[t_0, t_f]$ называется допустимым управлением.

Существует несколько видов критерия качества
\begin{enumerate}
  \item Критерий типа Майера $J(u)=\phi(x(t_f))+\int_{t_0}^{t_f}f_0(x(t),u(t),t)dt$ (терминальный критерий);
  \item Критерий типа Лагранжа $J(u)=\int_{t_0}^{t_f}f_0(x(t),u(t),t)dt$ (интегральный критерий);
  \item Критерий типа Больца $J(u)=\phi(x(t_f))+\int_{t_0}^{t_f}f_0(x(t),u(t),t)dt$;
  \item Критерий быстродействия $J(u)=t_f-t_0\to \min$.
\end{enumerate}

Допустимое управление $u^0(t), t\in[t_0, t_f]$ называется оптимальным, если оно минимизирует критерий качества $J(u^0)=minJ(u)$.

\section{Численные методы решения задач оптимального управления и программные средства}\label{1sec:Zou}
\subsection{Численные методы решения задач оптимального управления}\label{1sec:zou}
Рассмотрим некоторые методы решения задач оптимального управления.
\subsubsection{Метод штрафных функций}
\paragraph{Изложение метода}
Основная задача метода штрафных функций состоит в преобразовании задачи минимизации функции $z=f(x)$ с соответствующими ограничениями, наложенными на $х$, в задачу поиска минимума без ограничений функции  $Z=f(x)+P(x)$. Функция $P(x)$ является штрафной. Необходимо, чтобы при нарушении ограничений она «штрафовала» функцию $Z$, т.е. увеличивала её значение. В этом случае минимум функции $Z$ будет находиться внутри области ограничений. Функция $P(x)$, удовлетворяющая этому условию, может быть не единственной. Задачу минимизации можно сформулировать следующим образом:

минимизировать функцию $z=f(x)$ при ограничениях $c_j(x), j=1, 2, \dots, m$.

Функцию P(x) удобно записать следующим образом:
$$P(x)=r \sum_{j=1}^{m}\frac{1}{c_j(x)},$$
 где $r$ – положительная величина. Тогда функция $Z=\varphi(x,r)$ принимает вид
 $$Z=\varphi(x,r)=f(x)+r \sum_{j=1}^{m}\frac{1}{c_j(x)}$$

Если $х$ принимает допустимые значения, т.е. значения, для которых $c_j \geq 0$ , то Z принимает значения, которые больше соответствующих значений f(x) (истинной целевой функции данной задачи), и разность можно уменьшить за счет того, что $r$ может быть очень малой величиной. Но если $х$ принимает значения, которые хотя и являются допустимыми, но близки к границе области ограничений, и по крайней мере одна из функций $c_j(x)$ близка к нулю, тогда значения функции $P(x)$, и следовательно значения функции$ Z$ станут очень велики. Таким образом, влияние функции $P(x)$ состоит в создании «гребня с крутыми краями» вдоль каждой границы области ограничений. Следовательно, если поиск начнется из допустимой точки и осуществляется поиск минимума функции $\varphi(x,r)$ без ограничений, то минимум, конечно, будет достигаться внутри допустимой области для задачи с ограничениями. Полагая $r $ достаточно малой величиной, для того чтобы влияние $P(x)$ было малым в точке минимума, мы можем сделать точку минимума функции $\varphi(x,r)$ без ограничений совпадающей с точкой минимума задачи с ограничениями.

\paragraph{Алгоритм метода штрафных функций}
Пусть имеется следующая задача: Минимизировать f(x) при ограничениях $g_i(x) \geq 0 i=\overline{1,m}$
\subparagraph{Начальный этап}
Выбрать $\epsilon \ge 0$ в качестве константы остановки, начальную допустимую точку $x^0 \in R^n$, для которой $g_i(x^0) \ge 0, i=\overline{1,m}$, скаляр $r_0$ и $0 \le \beta \le 1$. Положить $k=1$ и перейти к основному этапу.
\subparagraph{Основной этап}
 При исходной точке $x_k$ решить следующую задачу безусловной оптимизации:
$ P(x,r)=f(x)+r\sum_{i=1}^mR_i(g_i(x))\omega_i$ минимизировать, где

$r\ge 0$ - параметр, значения которого убывают с каждой итерации $R_i(t) \to \infty $ при $t \to 0; \omega_i$ - положительные весовые коэффициенты.

Примерами штрафных функций являются:
\begin{itemize}
  \item обратная функция$ R_i(g_i(x))=\frac{1}{g_i(x)}$

  \item логарифмическая функция $R_i(g_i(x))=-ln(g_i(x))$
\end{itemize}



Положить $x_{k+1}$ равным оптимальному решению задачи минимизации и перейти ко второму шагу.

Минимизация штрафной функцию может быть выполнена любым методом безусловной оптимизации, например, градиентным.

Если $r_k\sum R(g_i(x_{k+1}))\omega_i<\epsilon$, то остановиться. Решение является искомым.

В противном случае положить $r_{k+1}=\beta r_k$. Изменить $k=k+1$ и перейти к первому шагу (k+1)-й итерации.

\subsubsection{Метод сопряжённых градиентов}

Метод сопряжённых градиентов — итерационный метод для безусловной оптимизации в многомерном пространстве. Основным достоинством метода является то, что он решает квадратичную задачу оптимизации за конечное число шагов. Поэтому, сначала описывается метод сопряжённых градиентов для оптимизации квадратичного функционала, выводятся итерационные формулы, приводятся оценки скорости сходимости. После этого показывается, как метод сопряжённых обобщается для оптимизации произвольного функционала, рассматриваются различные варианты метода, обсуждается сходимость.

\paragraph{Постановка задачи оптимизации}

Пусть задано множество  $X \subset R^n$  и на этом множестве определена целевая функция (objective function) $f \colon R^n \mapsto R$. Задача оптимизации состоит в нахождении на множестве X точной верхней или точной нижней грани целевой функции.
Множество точек, на которых достигается нижняя грань целевой функции обозначается $X_*$ .
%$X_* = {x \in X| f(x) = inf \limits_{x \in X} f(x) }$
Если  $X = R^n$ , то задача оптимизации называется безусловной. Если  $X \neq R^n, $ то задача оптимизации называется условной.

 \paragraph{Будем решать задачу:}

$F(x) \to min, \quad x \in R^n $.
F(x)  - непрерывно дифференцируемая в $R^n$  функция. Чтобы модифицировать метод сопряжённых градиентов для решения этой задачи необходимо получить для $p_k, \alpha_k, \beta_k$  формулы, в которые не входит матрица А:

$\alpha_k =argmin\lim_{\alpha_k} F(x_{k-1} + \alpha_k  p_k)$
 $p_{k+1} = - F'(x_{k}) + \beta_{k} p_{k}$
 $\beta_k$  можно вычислять по одной из трёх формул:
 \begin{itemize}
   \item $\beta_k = - \frac{\langle F'(x_{k} ), F'(x_{k}) \rangle}{\langle F'(x_{k-1}), F'(x_{k-1}) \rangle} $ - Метод Флетчера - Ривса.
   \item $\beta_k = \frac{\langle F'(x_{k}), F'(x_k) - F'(x_{k-1} ) \rangle}{\langle F'(x_{k - 1}), F'(x_{k - 1}) \rangle}$  - Метод Полака - Райбера.
   \item $\beta_k = \frac{\langle F''(x_k) p_k, F'(x_k) \rangle}{\langle F''(x_{k - 1})p_k, p_k \rangle}$
 \end{itemize}



Если функция $F(x)$ - квадратичная и строго выпуклая, то все три формулы дают одинаковый результат. Если F(x) - произвольная функция, то каждой из формул cоответствует своя модификация метода сопряжённых градиентов. Третья формула используется редко, так как она требует, чтобы функция $F(x) \in C^2(R^n)$ и вычисления гессиана функции $F(x)$ на каждом шаге метода.
\subparagraph{Анализ метода}
Если функция $F(x)$ - не квадратичная, метод сопряжённых градиентов может и не сходиться за конечное число шагов. Кроме того, точное вычисление $\alpha_k$ на каждом шаге возможно только в редких случаях. Поэтому накопление погрешностей приводит к тому, что вектора  $p_k $ перестают указывать направление убывания функции $F(x)$. Тогда на каком-то шаге полагают $\beta_k = 0$. Совокупность всех номеров k, при которых принимается $\beta_k = 0$, обозначим за $I_0$. Номера $k \in I_0 $ называются моментами обновления метода. На практике часто выбирают $I_0 = \{n, 2n, 3n, \dots \}$, где n - размерность пространства.

\subparagraph{Сходимость метода}
Для метода Флетчера - Ривса существует теорема о сходимости, накладывающая не слишком жёсткие условия на минимизируемую функцию F(x):
Теорема.

Пусть  $F(x) \in C^1(R^n)$ и выполняются следующие условия:

 $\alpha_k$  удовлетворяет строгим условиям Вольфа:
 $F(x_{k -1} + \alpha_k p_k ) \leq F(x_{k - 1}) +  c_1 \alpha_k \langle F'(x_{k - 1}), p_k \rangle | \langle F'(x_{k -1} + \alpha_k p_k), p_k \rangle  \leq c_2 |\langle F'(x_{k - 1}), p_k \rangle|$ где  $0 < c_1 < c_2 < 1/2$
Множество  $M = \{ x | F(x) \leq F(x_0) \}$ ограничено
Производная F'(x) удовлетворяет условию Липшица с константой L в некоторой окрестности  N
множества $M: ||F'(x_1) - F'(x_2)|| \leq L ||x_1 - x_2|| \qquad \forall x_1, x_2 \in N $.
Тогда
 $\lim \limits_{k \to \infty} inf ||F'(x_k)| = 0$
Для метода Полака-Райбера доказана сходимость в предположении, что F(x) - строго выпуклая функция. В общем случае доказать сходимость метода Полака - Райбера невозможно. Напоротив, верна следующая теорема:

Предположим, что в методе Полака-Райбера значения $\alpha_k$ на каждом шаге вычисляются точно. Тогда существует функция $F : R^3 \mapsto R, \quad F(x) \in C^2(R^3)$, и начальное приближение $x_0$ , такие что $\exists \delta > 0, \forall k = 0, 1, 2, ... \quad ||f(x_k)|| > \delta$.

Тем не менее, на практике метод Полака-Райбера работает лучше.
Наиболее распространённые критерии останова на практике: Норма градиента становится меньше некоторого порога
Значение функции в течении m последовательных итераций почти не изменилось

\subsubsection{Метод последовательных приближений}

Пусть некоторый процесс описывается системой дифференциальных уравнений вида

\begin{equation}\label{mpp1}
  \dot X=f(x,t)+b(x,t)\dot u(t), 0\le t\le T.
\end{equation}

Задача будет состоять в минимизации функционала, заданного на решениях уравнения (\ref{mpp1})

\begin{equation}\label{mpp2}
  J=\varphi(x(T),T)\to \min
\end{equation}
в фиксированный момент времени $T$ и при наличии ограничений типа равенства 

\begin{equation}\label{mpp3}
  x(0)=x_1; u(0)=0; h(x(T),T)=0, h\in R^{N_h},
\end{equation}
$$g(x(t),t)=0, 0\le t\le T, g\in R^{N_g}$$
и неравенства

\begin{equation}\label{mpp4}
  s(x(T),T)\le0, s\in R^{N_s},
\end{equation}
$$q(x(t),t)\le0, 0\le t\le T, q\in R^{N_q};$$

\subsection{Программные средства решения задач оптимального управления}
 Существуют встроенные средства и специализированные пакеты для Matlab
(YALMIP, ACADO, CasADi) и Pyton (CasADi) для моделирования и
численного решения задач оптимизации и оптимального управления. 